import json, torch, torch.nn as nn, torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from transformers import AutoTokenizer, AutoModel
from pathlib import Path
import os, shutil, tempfile

# ÏÑ§Ï†ï
MODEL_NAME = "bert-base-multilingual-cased"
LR, EPOCHS, BS, MAX_LEN = 2e-5, 5, 16, 256 # EpochÎ•º 3 -> 5Î°ú Ï°∞Í∏à ÎäòÎ¶¨Îäî Í≤É Ï∂îÏ≤ú
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

class JLDataset(Dataset):
    def __init__(self, path, tok):
        self.rows = [json.loads(l) for l in open(path, "r", encoding="utf-8")]
        self.tok = tok
    def __len__(self): return len(self.rows)
    def __getitem__(self, i):
        r = self.rows[i]
        enc = self.tok(r["text"], padding="max_length", truncation=True,
                       max_length=MAX_LEN, return_tensors="pt")
        item = {k: v.squeeze(0) for k, v in enc.items()}
        # Target shape: scalar (float)
        item["A"] = torch.tensor(r["A"], dtype=torch.float)
        return item

# üî¥ [ÌïµÏã¨ ÏàòÏ†ï] SoftmaxÎ•º Ï†úÍ±∞ÌïòÍ≥† ÏàúÏàò ÌöåÍ∑Ä(Regression) Î™®Îç∏Î°ú Î≥ÄÍ≤Ω
class TrafficRegressor(nn.Module):
    def __init__(self, bert):
        super().__init__()
        self.bert = bert
        # Í≥ºÏ†ÅÌï© Î∞©ÏßÄÎ•º ÏúÑÌïú Dropout Ï∂îÍ∞Ä (XAI ÏïàÏ†ïÏÑ± Ìñ•ÏÉÅ)
        self.dropout = nn.Dropout(0.1)
        # Ï∂úÎ†• Ï∞®ÏõêÏùÑ 2 -> 1Î°ú Î≥ÄÍ≤Ω
        self.regressor = nn.Linear(bert.config.hidden_size, 1)

    def forward(self, input_ids, attention_mask):
        out = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        # CLS ÌÜ†ÌÅ∞ Ï∂îÏ∂ú
        h_cls = out.last_hidden_state[:, 0]
        h_cls = self.dropout(h_cls)
        
        # Softmax ÏóÜÏù¥ Î∞îÎ°ú Ïã§ÏàòÍ∞í ÏòàÏ∏° (0~100 ÏÇ¨Ïù¥Ïùò Í∞í ÌïôÏäµ)
        predA = self.regressor(h_cls)
        
        # Ï∞®Ïõê Ï∂ïÏÜå: [Batch, 1] -> [Batch]
        return predA.squeeze(-1)

def evaluate(model, dl):
    model.eval()
    mae = 0
    n = 0
    with torch.no_grad():
        for b in dl:
            ids = b["input_ids"].to(DEVICE)
            mask = b["attention_mask"].to(DEVICE)
            y = b["A"].to(DEVICE)
            
            predA = model(ids, mask)
            
            # ÏòàÏ∏°Í∞í Î≤îÏúÑ Ï†úÌïú (ÏòµÏÖò: 0~100 Î≤óÏñ¥ÎÇòÎ©¥ ÏûòÎùºÏ§å)
            # predA = torch.clamp(predA, 0, 100) 
            
            mae += torch.abs(predA - y).sum().item()
            n += y.size(0)
    return mae / max(n, 1)

def main():
    # Ï†ÄÏû• Í≤ΩÎ°ú ÏÑ§Ï†ï
    ckpt_dir = Path("train/artifacts")
    ckpt_dir.mkdir(parents=True, exist_ok=True)

    # ‚ùó [Ï£ºÏùò] Î™®Îç∏ Íµ¨Ï°∞Í∞Ä Î∞îÎÄåÏóàÏúºÎØÄÎ°ú Í∏∞Ï°¥ model.ptÍ∞Ä ÏûàÎã§Î©¥ ÏÇ≠Ï†úÌïòÍ±∞ÎÇò Î¨¥ÏãúÌï¥Ïïº Ìï®
    # ÏïÑÏòà ÏÉàÎ°ú ÌïôÏäµÌïòÎäî Í≤ÉÏù¥Îãà Î°úÎìú Í≥ºÏ†ï ÏÉùÎûµ
    
    tok = AutoTokenizer.from_pretrained(MODEL_NAME)
    bert = AutoModel.from_pretrained(MODEL_NAME)
    
    # Î™®Îç∏ ÍµêÏ≤¥: TextOnlyHead -> TrafficRegressor
    model = TrafficRegressor(bert).to(DEVICE)

    ds_tr = JLDataset("train/train.jsonl", tok)
    ds_va = JLDataset("train/valid.jsonl", tok)
    dl_tr = DataLoader(ds_tr, batch_size=BS, shuffle=True)
    dl_va = DataLoader(ds_va, batch_size=BS)

    opt = optim.AdamW(model.parameters(), lr=LR)
    
    # Regression ÏÜêÏã§Ìï®Ïàò
    loss_fn = nn.SmoothL1Loss() 

    print("=== Training Start (Regression Mode) ===")
    for ep in range(1, EPOCHS+1):
        model.train()
        train_loss = 0
        for b in dl_tr:
            ids = b["input_ids"].to(DEVICE)
            mask = b["attention_mask"].to(DEVICE)
            y = b["A"].to(DEVICE)
            
            predA = model(ids, mask)
            
            loss = loss_fn(predA, y)
            
            opt.zero_grad()
            loss.backward()
            opt.step()
            train_loss += loss.item()
            
        val_mae = evaluate(model, dl_va)
        print(f"Epoch {ep}/{EPOCHS} | Train Loss: {train_loss/len(dl_tr):.4f} | Valid MAE: {val_mae:.2f}")

    # Ï†ÄÏû• (Í∏∞Ï°¥ Î°úÏßÅ Ïú†ÏßÄ)
    print("Saving model...")
    tmp_fd, tmp_path = tempfile.mkstemp(suffix=".pt")
    os.close(tmp_fd)
    try:
        torch.save(model.state_dict(), tmp_path, _use_new_zipfile_serialization=False)
        os.replace(tmp_path, ckpt_dir / "model.pt")
    except Exception as e:
        if os.path.exists(tmp_path): os.remove(tmp_path)
        raise e

    tok.save_pretrained(str(ckpt_dir))
    bert.save_pretrained(str(ckpt_dir))
    
    print(f"[Done] Artifacts saved at: {ckpt_dir.resolve()}")

if __name__ == "__main__":
    main()